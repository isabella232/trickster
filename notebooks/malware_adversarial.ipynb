{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "\n",
    "from trickster.search import a_star_search, ida_star_search\n",
    "\n",
    "\n",
    "from defaultcontext import with_default_context\n",
    "from profiled import Profiler, profiled\n",
    "\n",
    "MANIFEST_FEATURES = [    # corresponds to...\n",
    "    'provider',          # \"Hardware Components\" \n",
    "    'permission',        # \"Permissions\"\n",
    "    'activity',          # \"Components\" (185,729 / 218,951)\n",
    "    'service_receiver',  # \"Components\" (33,222  / 218,951)\n",
    "    'intent'             # \"Intents\"\n",
    "]                        # ... in the Grosse et al. paper\n",
    "\n",
    "seed = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record hashes corresponding to malware applications\n",
    "df = pd.read_csv('data/drebin_malware_sha256.csv')\n",
    "malware_hashes = set(df['sha256'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/drebin/'\n",
    "\n",
    "# Load the data and record the feature set\n",
    "data, labels, features = [], [], set()\n",
    "subset = 50 # use only a subset of the dataset\n",
    "\n",
    "for file_path in listdir(data_dir)[:subset]:\n",
    "    with open(data_dir + file_path) as f:\n",
    "        lines = [x.strip() for x in f]\n",
    "        if lines == '':\n",
    "            continue\n",
    "        data.append(lines)\n",
    "        features |= set(lines)\n",
    "        label = 1 if file_path in malware_hashes else 0\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_call: 50\n",
      "feature: 11\n",
      "url: 484\n",
      "service_receiver: 22\n",
      "permission: 51\n",
      "call: 19\n",
      "intent: 15\n",
      "real_permission: 21\n",
      "activity: 211\n",
      "provider: 3\n",
      "Sum of all features: 887.\n"
     ]
    }
   ],
   "source": [
    "# Provide statistics about the feature classes in the DREBIN dataset\n",
    "\n",
    "classes, seen = {}, set()\n",
    "for d in data:\n",
    "    for feature in d:\n",
    "        if feature in seen:\n",
    "            continue\n",
    "        seen.add(feature)\n",
    "        f = feature.split('::')[0]\n",
    "        if f == '':\n",
    "            continue\n",
    "        classes[f] = classes.get(f, 0) + 1\n",
    "        \n",
    "classes_count = sum(classes.values())\n",
    "\n",
    "for k, v in classes.items():\n",
    "    print('{}: {}'.format(k, v))\n",
    "print('Sum of all features: {}.'.format(classes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (50, 887). Shape of y: (50,).\n"
     ]
    }
   ],
   "source": [
    "# Fit a label encoder and transform the input data\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(features))\n",
    "\n",
    "encoded = []\n",
    "for i, x in enumerate(data):\n",
    "    if i != 0 and i % 500 == 0:\n",
    "        print('Label encoded {} examples.'.format(i))\n",
    "    e = label_encoder.transform(x)\n",
    "    encoded.append(e)\n",
    "\n",
    "# Create a sparse binary matrix from the input data\n",
    "indptr = np.cumsum([0] + [len(x) for x in encoded])\n",
    "indices = np.concatenate(encoded)\n",
    "ones = np.ones(indices.size)\n",
    "\n",
    "N, K = len(data), len(features)\n",
    "X = csr_matrix((ones, indices, indptr), shape=(N, K))\n",
    "y = np.array(labels)\n",
    "print('Shape of X: {}. Shape of y: {}.'.format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 887), (45,), (5, 887), (5,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to save & load data for future use\n",
    "\n",
    "# save_npz('data/tmp/malware_X.npz', X)\n",
    "# np.save('data/tmp/malware_y.npy', y)\n",
    "\n",
    "# X = load_npz('data/tmp/malware_X.npz')\n",
    "# y = np.load('data/tmp/malware_y.npy')\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for a constant model f(x) = 0 is: 86.67%.\n",
      "Training accuracy is: 100.00%. Best C is: 1.1500. Class weight: balanced. Scoring: accuracy.\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression and perform CV\n",
    "\n",
    "Cs = np.arange(0.5, 1.5, 0.025)\n",
    "class_weight = 'balanced' # balanced or None\n",
    "scoring = 'accuracy' # accuracy or roc_auc\n",
    "\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=Cs, \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    penalty='l2',\n",
    "    scoring=scoring,\n",
    "    class_weight=class_weight,\n",
    "    random_state=seed\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get best score and C value\n",
    "mean_scores = np.mean(clf.scores_[1], axis=0)\n",
    "best_idx = np.argmax(mean_scores)\n",
    "best_score = mean_scores[best_idx]\n",
    "best_C = clf.Cs_[best_idx]\n",
    "\n",
    "constant_acc = 1 - sum(y_train) / len(y_train)\n",
    "print('Training score for a constant model f(x) = 0 is: {:.2f}%.'.format(constant_acc*100))\n",
    "print('Training accuracy is: {:.2f}%. Best C is: {:.4f}. Class weight: {}. Scoring: {}.'\n",
    "      .format(clf.score(X_train, y_train)*100, best_C, class_weight, scoring))\n",
    "\n",
    "# Training score for a constant model f(x) = 0 is: 95.11%.\n",
    "# Training accuracy is: 99.78%. Best C is: 0.7000. Class weight: balanced. Scoring: accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for a constant model f(x) = 0 is: 100.00%.\n",
      "Test accuracy is: 100.00%.\n"
     ]
    }
   ],
   "source": [
    "constant_acc = 1 - sum(y_test) / len(y_test)\n",
    "print('Test score for a constant model f(x) = 0 is: {:.2f}%.'.format(constant_acc*100))\n",
    "print('Test accuracy is: {:.2f}%.'.format(clf.score(X_test, y_test)*100))\n",
    "\n",
    "# Test score for a constant model f(x) = 0 is: 95.50%.\n",
    "# Test accuracy is: 97.40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide implemention of Algorithm 1 from Grosse et al. paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide helper classes and methods\n",
    "class LogisticRegressionScikitSaliencyOracle:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def eval(self, _):\n",
    "        return self.model.coef_[0]\n",
    "    \n",
    "def _get_manifest_map(label_encoder):    \n",
    "    manifest_map = {}\n",
    "    for i, c in enumerate(label_encoder.classes_):\n",
    "        feature_class = c.split('::')[0]\n",
    "        manifest_map[i] = feature_class in MANIFEST_FEATURES\n",
    "    return manifest_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1 from Grosse et al. paper\n",
    "def find_adversarial_grosse(x, clf, oracle, manifest_map, k=20, return_path=False):\n",
    "    \n",
    "    if clf.predict([x]) == 0:\n",
    "        raise Exception('Initial example is already classified as bening.')\n",
    "        \n",
    "    if return_path:\n",
    "        path = [x]\n",
    "        \n",
    "    x_star = np.array(x, dtype='intc')\n",
    "    distortions = 0\n",
    "    \n",
    "    while clf.predict([x_star]) != 0 and distortions < k:\n",
    "        derivative = oracle.eval(x_star)\n",
    "        idxs = np.argsort(derivative)\n",
    "        \n",
    "        for i, idx in enumerate(idxs):\n",
    "            \n",
    "            # Check if changing the feature is permitted.\n",
    "            if x_star[idx] == 0 and manifest_map[idx]:\n",
    "                x_star[idx] = 1\n",
    "                if return_path:\n",
    "                    path.append(np.array(x_star))\n",
    "                break\n",
    "                \n",
    "            if i == len(idxs) - 1:\n",
    "                raise Exception('Adversarial example is impossible to create.')\n",
    "                \n",
    "        distortions += 1\n",
    "        \n",
    "    if distortions == k:\n",
    "        raise Exception('Distortion bound reached.')\n",
    "        \n",
    "    if return_path:\n",
    "        return x_star, distortions, path\n",
    "    else:\n",
    "        return x_star, distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial example for example: 0.\n",
      "Start probability: 0.98. Resulting probability: 0.50. Cost: 59.\n",
      "\n",
      "Crafting adversarial example for example: 2.\n",
      "Start probability: 0.97. Resulting probability: 0.49. Cost: 53.\n",
      "\n",
      "Crafting adversarial example for example: 21.\n",
      "Start probability: 0.97. Resulting probability: 0.49. Cost: 50.\n",
      "\n",
      "Crafting adversarial example for example: 23.\n",
      "Start probability: 0.90. Resulting probability: 0.49. Cost: 25.\n",
      "\n",
      "Crafting adversarial example for example: 26.\n",
      "Start probability: 0.97. Resulting probability: 0.49. Cost: 57.\n",
      "\n",
      "Crafting adversarial example for example: 41.\n",
      "Start probability: 0.96. Resulting probability: 0.50. Cost: 49.\n"
     ]
    }
   ],
   "source": [
    "oracle = LogisticRegressionScikitSaliencyOracle(clf)\n",
    "manifest_map = _get_manifest_map(label_encoder) # checks if feature belongs to manifest \n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    \n",
    "    # Transform the example from compressed matrix format to numpy array.\n",
    "    x = x.toarray()[0] \n",
    "    \n",
    "    if clf.predict([x]) == 1:\n",
    "        print('\\nCrafting adversarial example for example: {}.'.format(i))\n",
    "        try:\n",
    "            x_adv, cost = find_adversarial_grosse(x, clf, oracle, manifest_map, k=100)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        x_prob, x_adv_prob = clf.predict_proba([x])[0, 1], clf.predict_proba([x_adv])[0, 1]\n",
    "        print('Start probability: {:.2f}. Resulting probability: {:.2f}. Cost: {}.'.format(x_prob, x_adv_prob, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide implemention for A* search on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_default_context(use_empty_init=True)\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def increment(self):\n",
    "        self.cnt += 1\n",
    "        \n",
    "    def count(self):\n",
    "        return self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that can be altered\n",
    "manifest_features = [f for (f,b) in manifest_map.items() if b]\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, x):\n",
    "        self.root = x\n",
    "\n",
    "    def expand(self):\n",
    "        \"\"\"Generate all children of the current node.\"\"\"\n",
    "        \n",
    "        # Increment the counter of expanded nodes.\n",
    "        counter = Counter.get_default()\n",
    "        counter.increment()\n",
    "        \n",
    "        children = []\n",
    "        \n",
    "        for feat_idx in manifest_features:\n",
    "            \n",
    "            # Skip if the feature is already set.\n",
    "            if self.root[feat_idx] == 1:\n",
    "                continue\n",
    "                \n",
    "            child = np.array(self.root)\n",
    "            child[feat_idx] = 1\n",
    "            children.append(child)\n",
    "            \n",
    "        return children\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Node({})'.format(self.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expand_fn(x, p_norm=1, **kwargs):\n",
    "    \"\"\"Wrap the example in `Node`, expand the node, and compute the costs.\n",
    "    \n",
    "    Returns a list of tuples (child, cost)\n",
    "    \"\"\"\n",
    "    node = Node(x, **kwargs)\n",
    "    children = node.expand()\n",
    "    costs = [np.linalg.norm(x - c, ord=p_norm) for c in children]         \n",
    "    return list(zip(children, costs))\n",
    "\n",
    "def _goal_fn(x, clf, target_confidence=0.5):\n",
    "    \"\"\"Tell whether the example has reached the goal.\"\"\"\n",
    "    return clf.predict_proba([x])[0, 1] <= target_confidence\n",
    "\n",
    "def _heuristic_fn(x, clf, q_norm=np.inf):\n",
    "    \"\"\"Distance to the decision boundary of a logistic regression classifier.\n",
    "    \n",
    "    By default the distance is w.r.t. L1 norm. This means that the denominator\n",
    "    has to be in terms of the Holder dual norm (`q_norm`), so L-inf. I know,\n",
    "    this interface is horrible.\n",
    "    \n",
    "    NOTE: The value has to be zero if the example is already on the target side\n",
    "    of the boundary.\n",
    "    \"\"\"\n",
    "    score = clf.decision_function([x])[0]\n",
    "    if score <= 0:\n",
    "        return 0.0\n",
    "    h = np.abs(score) / np.linalg.norm(clf.coef_[0, manifest_features], ord=q_norm)    \n",
    "    return h\n",
    "\n",
    "def hash_fn(x):\n",
    "    \"\"\"Hash function for examples.\"\"\"\n",
    "    return hash(x.tostring())\n",
    "\n",
    "@profiled\n",
    "def find_adversarial(x, clf, p_norm=1, q_norm=np.inf,\n",
    "                     target_confidence=0.5, return_path=False, **kwargs):\n",
    "    \"\"\"Transform an example until it is classified with target confidence.\"\"\" \n",
    "\n",
    "    if clf.predict_proba([x])[0, 1] <= target_confidence:\n",
    "        raise Exception('Initial example is already classified as bening.')        \n",
    "    return a_star_search(\n",
    "        start_node=x, \n",
    "        expand_fn=lambda x: _expand_fn(x, p_norm=p_norm, **kwargs), \n",
    "        goal_fn=lambda x: _goal_fn(x, clf, target_confidence), \n",
    "        heuristic_fn=lambda x: _heuristic_fn(x, clf, q_norm=q_norm), \n",
    "        hash_fn=hash_fn,\n",
    "        return_path=return_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run experiments to compare JSMA with our heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial example for example: 0.\n",
      "Cost using Grosse algorithm: 59. Using our heuristic: 60.\n",
      "\n",
      "Crafting adversarial example for example: 2.\n",
      "Cost using Grosse algorithm: 53. Using our heuristic: 53.\n",
      "\n",
      "Crafting adversarial example for example: 21.\n",
      "Cost using Grosse algorithm: 50. Using our heuristic: 50.\n",
      "\n",
      "Crafting adversarial example for example: 23.\n",
      "Cost using Grosse algorithm: 25. Using our heuristic: 25.\n",
      "\n",
      "Crafting adversarial example for example: 26.\n",
      "Cost using Grosse algorithm: 57. Using our heuristic: 57.\n",
      "\n",
      "Crafting adversarial example for example: 41.\n",
      "Cost using Grosse algorithm: 49. Using our heuristic: 50.\n"
     ]
    }
   ],
   "source": [
    "oracle = LogisticRegressionScikitSaliencyOracle(clf)\n",
    "manifest_map = _get_manifest_map(label_encoder) # checks if feature belongs to manifest \n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    \n",
    "    # Transform the example from compressed matrix format to numpy array.\n",
    "    x = x.toarray()[0] \n",
    "\n",
    "    if clf.predict([x]) == 1:\n",
    "        print('\\nCrafting adversarial example for example: {}.'.format(i))\n",
    "        \n",
    "        # Try finding adversarial example using JSMA with distortion bound k = 100.\n",
    "        try:\n",
    "            x_adv_grosse, cost_grosse = find_adversarial_grosse(x, clf, oracle, manifest_map, k=100)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        # Try finding adversarial example using our heuristic with A* search.\n",
    "        x_adv, cost = find_adversarial(x, clf, p_norm=1, q_norm=np.inf)\n",
    "        \n",
    "        assert clf.predict([x_adv_grosse]) == 0 and clf.predict([x_adv]) == 0\n",
    "        \n",
    "        print('Cost using Grosse algorithm: {}. Using our heuristic: {}.'.format(cost_grosse, int(cost)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
