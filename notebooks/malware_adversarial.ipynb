{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "\n",
    "from trickster.search import a_star_search, ida_star_search\n",
    "\n",
    "from defaultcontext import with_default_context\n",
    "from profiled import Profiler, profiled\n",
    "\n",
    "MANIFEST_FEATURES = [    # corresponds to...\n",
    "    'provider',          # \"Hardware Components\" \n",
    "    'permission',        # \"Permissions\"\n",
    "    'activity',          # \"Components\" (185,729 / 218,951)\n",
    "    'service_receiver',  # \"Components\" (33,222  / 218,951)\n",
    "    'intent'             # \"Intents\"\n",
    "]                        # ... in the Grosse et al. paper\n",
    "\n",
    "seed = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record hashes corresponding to malware applications\n",
    "df = pd.read_csv('../data/drebin_malware_sha256.csv')\n",
    "malware_hashes = set(df['sha256'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/drebin/'\n",
    "\n",
    "# Load the data and record the feature set\n",
    "data, labels, features = [], [], set()\n",
    "subset = 1000 # use only a subset of the dataset\n",
    "\n",
    "for file_path in listdir(data_dir)[:subset]:\n",
    "    with open(data_dir + file_path) as f:\n",
    "        lines = [x.strip() for x in f]\n",
    "        if lines == '':\n",
    "            continue\n",
    "        data.append(lines)\n",
    "        features |= set(lines)\n",
    "        label = 1 if file_path in malware_hashes else 0\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_call: 124\n",
      "feature: 21\n",
      "url: 6167\n",
      "service_receiver: 656\n",
      "permission: 180\n",
      "call: 114\n",
      "intent: 203\n",
      "real_permission: 40\n",
      "activity: 3238\n",
      "provider: 76\n",
      "Sum of all features: 10819.\n"
     ]
    }
   ],
   "source": [
    "# Provide statistics about the feature classes in the DREBIN dataset\n",
    "\n",
    "classes, seen = {}, set()\n",
    "for d in data:\n",
    "    for feature in d:\n",
    "        if feature in seen:\n",
    "            continue\n",
    "        seen.add(feature)\n",
    "        f = feature.split('::')[0]\n",
    "        if f == '':\n",
    "            continue\n",
    "        classes[f] = classes.get(f, 0) + 1\n",
    "        \n",
    "classes_count = sum(classes.values())\n",
    "\n",
    "for k, v in classes.items():\n",
    "    print('{}: {}'.format(k, v))\n",
    "print('Sum of all features: {}.'.format(classes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded 500 examples.\n",
      "Shape of X: (1000, 10819). Shape of y: (1000,).\n"
     ]
    }
   ],
   "source": [
    "# Fit a label encoder and transform the input data\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(features))\n",
    "\n",
    "encoded = []\n",
    "for i, x in enumerate(data):\n",
    "    if i != 0 and i % 500 == 0:\n",
    "        print('Label encoded {} examples.'.format(i))\n",
    "    e = label_encoder.transform(x)\n",
    "    encoded.append(e)\n",
    "\n",
    "# Create a sparse binary matrix from the input data\n",
    "indptr = np.cumsum([0] + [len(x) for x in encoded])\n",
    "indices = np.concatenate(encoded)\n",
    "ones = np.ones(indices.size)\n",
    "\n",
    "N, K = len(data), len(features)\n",
    "X = csr_matrix((ones, indices, indptr), shape=(N, K))\n",
    "y = np.array(labels)\n",
    "print('Shape of X: {}. Shape of y: {}.'.format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 10819), (900,), (100, 10819), (100,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to save & load data for future use\n",
    "\n",
    "# save_npz('data/tmp/malware_X.npz', X)\n",
    "# np.save('data/tmp/malware_y.npy', y)\n",
    "\n",
    "# X = load_npz('data/tmp/malware_X.npz')\n",
    "# y = np.load('data/tmp/malware_y.npy')\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for a constant model f(x) = 0 is: 94.56%.\n",
      "Training accuracy is: 99.78%. Best C is: 0.5750. Class weight: balanced. Scoring: accuracy.\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression and perform CV\n",
    "\n",
    "Cs = np.arange(0.5, 1.5, 0.025)\n",
    "class_weight = 'balanced' # balanced or None\n",
    "scoring = 'accuracy' # accuracy or roc_auc\n",
    "\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=Cs, \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    penalty='l2',\n",
    "    scoring=scoring,\n",
    "    class_weight=class_weight,\n",
    "    random_state=seed\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get best score and C value\n",
    "mean_scores = np.mean(clf.scores_[1], axis=0)\n",
    "best_idx = np.argmax(mean_scores)\n",
    "best_score = mean_scores[best_idx]\n",
    "best_C = clf.Cs_[best_idx]\n",
    "\n",
    "constant_acc = 1 - sum(y_train) / len(y_train)\n",
    "print('Training score for a constant model f(x) = 0 is: {:.2f}%.'.format(constant_acc*100))\n",
    "print('Training accuracy is: {:.2f}%. Best C is: {:.4f}. Class weight: {}. Scoring: {}.'\n",
    "      .format(clf.score(X_train, y_train)*100, best_C, class_weight, scoring))\n",
    "\n",
    "# Training score for a constant model f(x) = 0 is: 95.11%.\n",
    "# Training accuracy is: 99.78%. Best C is: 0.7000. Class weight: balanced. Scoring: accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for a constant model f(x) = 0 is: 96.00%.\n",
      "Test accuracy is: 98.00%.\n"
     ]
    }
   ],
   "source": [
    "constant_acc = 1 - sum(y_test) / len(y_test)\n",
    "print('Test score for a constant model f(x) = 0 is: {:.2f}%.'.format(constant_acc*100))\n",
    "print('Test accuracy is: {:.2f}%.'.format(clf.score(X_test, y_test)*100))\n",
    "\n",
    "# Test score for a constant model f(x) = 0 is: 95.50%.\n",
    "# Test accuracy is: 97.40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide implemention of Algorithm 1 from Grosse et al. paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide helper classes and methods\n",
    "class LogisticRegressionScikitSaliencyOracle:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def eval(self, _):\n",
    "        return self.model.coef_[0]\n",
    "\n",
    "def get_manifest_set(label_encoder):    \n",
    "    manifest_set = set()\n",
    "    for i, c in enumerate(label_encoder.classes_):\n",
    "        feature_class = c.split('::')[0]\n",
    "        if feature_class in MANIFEST_FEATURES:\n",
    "            manifest_set.add(i)\n",
    "    return manifest_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1 from Grosse et al. paper\n",
    "@profiled\n",
    "def find_adversarial_grosse(x, clf, oracle, manifest_set, target_confidence=0.5, k=20, return_path=False):\n",
    "    \n",
    "    if clf.predict_proba([x])[0, 1] <= target_confidence:\n",
    "        raise Exception('Initial example is already classified as bening.')\n",
    "        \n",
    "    if return_path:\n",
    "        path = [x]\n",
    "        \n",
    "    x_star = np.array(x, dtype='intc')\n",
    "    distortions = 0\n",
    "    \n",
    "    while clf.predict_proba([x_star])[0, 1] > target_confidence and distortions < k:\n",
    "        derivative = oracle.eval(x_star)\n",
    "        idxs = np.argsort(derivative)\n",
    "        \n",
    "        for i, idx in enumerate(idxs):\n",
    "            \n",
    "            # Check if changing the feature is permitted.\n",
    "            if x_star[idx] == 0 and idx in manifest_set:\n",
    "                x_star[idx] = 1\n",
    "                if return_path:\n",
    "                    path.append(np.array(x_star))\n",
    "                break\n",
    "                \n",
    "            if i == len(idxs) - 1:\n",
    "                raise Exception('Adversarial example is impossible to create.')\n",
    "                \n",
    "        distortions += 1\n",
    "        \n",
    "    if distortions == k:\n",
    "        raise Exception('Distortion bound reached.')\n",
    "        \n",
    "    if return_path:\n",
    "        return x_star, distortions, path\n",
    "    else:\n",
    "        return x_star, distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial example for example: 0.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 16.\n",
      "\n",
      "Crafting adversarial example for example: 2.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 15.\n",
      "\n",
      "Crafting adversarial example for example: 21.\n",
      "Start probability: 0.98. Resulting probability: 0.46. Cost: 12.\n",
      "\n",
      "Crafting adversarial example for example: 23.\n",
      "Start probability: 0.93. Resulting probability: 0.45. Cost: 7.\n",
      "\n",
      "Crafting adversarial example for example: 26.\n",
      "Start probability: 0.98. Resulting probability: 0.49. Cost: 16.\n",
      "\n",
      "Crafting adversarial example for example: 41.\n",
      "Start probability: 0.98. Resulting probability: 0.49. Cost: 13.\n",
      "\n",
      "Crafting adversarial example for example: 51.\n",
      "Start probability: 1.00. Resulting probability: 0.48. Cost: 40.\n",
      "\n",
      "Crafting adversarial example for example: 68.\n",
      "Start probability: 0.96. Resulting probability: 0.44. Cost: 10.\n",
      "\n",
      "Crafting adversarial example for example: 95.\n",
      "Start probability: 0.95. Resulting probability: 0.48. Cost: 9.\n",
      "\n",
      "Crafting adversarial example for example: 109.\n",
      "Start probability: 0.97. Resulting probability: 0.48. Cost: 11.\n",
      "\n",
      "Crafting adversarial example for example: 133.\n",
      "Start probability: 0.98. Resulting probability: 0.45. Cost: 12.\n",
      "\n",
      "Crafting adversarial example for example: 135.\n",
      "Start probability: 0.97. Resulting probability: 0.50. Cost: 18.\n",
      "\n",
      "Crafting adversarial example for example: 141.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 16.\n",
      "\n",
      "Crafting adversarial example for example: 145.\n",
      "Start probability: 0.91. Resulting probability: 0.45. Cost: 6.\n",
      "\n",
      "Crafting adversarial example for example: 150.\n",
      "Start probability: 0.98. Resulting probability: 0.48. Cost: 13.\n",
      "\n",
      "Crafting adversarial example for example: 155.\n",
      "Start probability: 0.90. Resulting probability: 0.48. Cost: 5.\n",
      "\n",
      "Crafting adversarial example for example: 184.\n",
      "Start probability: 1.00. Resulting probability: 0.47. Cost: 32.\n",
      "\n",
      "Crafting adversarial example for example: 185.\n",
      "Start probability: 0.98. Resulting probability: 0.50. Cost: 16.\n",
      "\n",
      "Crafting adversarial example for example: 194.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 17.\n",
      "\n",
      "Crafting adversarial example for example: 201.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 24.\n",
      "\n",
      "Crafting adversarial example for example: 217.\n",
      "Start probability: 0.97. Resulting probability: 0.48. Cost: 11.\n",
      "\n",
      "Crafting adversarial example for example: 237.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 16.\n",
      "\n",
      "Crafting adversarial example for example: 263.\n",
      "Start probability: 0.93. Resulting probability: 0.45. Cost: 7.\n",
      "\n",
      "Crafting adversarial example for example: 278.\n",
      "Start probability: 0.98. Resulting probability: 0.49. Cost: 13.\n",
      "\n",
      "Crafting adversarial example for example: 349.\n",
      "Start probability: 0.76. Resulting probability: 0.47. Cost: 4.\n",
      "\n",
      "Crafting adversarial example for example: 393.\n",
      "Start probability: 1.00. Resulting probability: 0.49. Cost: 32.\n",
      "\n",
      "Crafting adversarial example for example: 403.\n",
      "Start probability: 1.00. Resulting probability: 0.49. Cost: 40.\n",
      "\n",
      "Crafting adversarial example for example: 404.\n",
      "Start probability: 0.97. Resulting probability: 0.47. Cost: 12.\n",
      "\n",
      "Crafting adversarial example for example: 421.\n",
      "Start probability: 0.93. Resulting probability: 0.45. Cost: 8.\n",
      "\n",
      "Crafting adversarial example for example: 434.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 19.\n",
      "\n",
      "Crafting adversarial example for example: 457.\n",
      "Start probability: 1.00. Resulting probability: 0.47. Cost: 32.\n",
      "\n",
      "Crafting adversarial example for example: 463.\n",
      "Start probability: 0.98. Resulting probability: 0.50. Cost: 13.\n",
      "\n",
      "Crafting adversarial example for example: 470.\n",
      "Start probability: 0.90. Resulting probability: 0.43. Cost: 6.\n",
      "\n",
      "Crafting adversarial example for example: 482.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 15.\n",
      "\n",
      "Crafting adversarial example for example: 503.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 14.\n",
      "\n",
      "Crafting adversarial example for example: 540.\n",
      "Start probability: 0.99. Resulting probability: 0.50. Cost: 19.\n",
      "\n",
      "Crafting adversarial example for example: 562.\n",
      "Start probability: 1.00. Resulting probability: 0.49. Cost: 32.\n",
      "\n",
      "Crafting adversarial example for example: 571.\n",
      "Start probability: 0.99. Resulting probability: 0.50. Cost: 19.\n",
      "\n",
      "Crafting adversarial example for example: 608.\n",
      "Start probability: 0.78. Resulting probability: 0.49. Cost: 5.\n",
      "\n",
      "Crafting adversarial example for example: 684.\n",
      "Start probability: 0.99. Resulting probability: 0.50. Cost: 26.\n",
      "\n",
      "Crafting adversarial example for example: 694.\n",
      "Start probability: 0.52. Resulting probability: 0.43. Cost: 1.\n",
      "\n",
      "Crafting adversarial example for example: 724.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 19.\n",
      "\n",
      "Crafting adversarial example for example: 725.\n",
      "Start probability: 0.98. Resulting probability: 0.47. Cost: 13.\n",
      "\n",
      "Crafting adversarial example for example: 731.\n",
      "Start probability: 0.93. Resulting probability: 0.48. Cost: 7.\n",
      "\n",
      "Crafting adversarial example for example: 747.\n",
      "Start probability: 0.97. Resulting probability: 0.48. Cost: 11.\n",
      "\n",
      "Crafting adversarial example for example: 761.\n",
      "Start probability: 1.00. Resulting probability: 0.50. Cost: 60.\n",
      "\n",
      "Crafting adversarial example for example: 781.\n",
      "Start probability: 0.98. Resulting probability: 0.45. Cost: 14.\n",
      "\n",
      "Crafting adversarial example for example: 819.\n",
      "Start probability: 0.95. Resulting probability: 0.45. Cost: 9.\n",
      "\n",
      "Crafting adversarial example for example: 820.\n",
      "Start probability: 1.00. Resulting probability: 0.48. Cost: 30.\n",
      "\n",
      "Crafting adversarial example for example: 824.\n",
      "Start probability: 0.98. Resulting probability: 0.47. Cost: 18.\n",
      "\n",
      "Crafting adversarial example for example: 828.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 15.\n",
      "\n",
      "Crafting adversarial example for example: 859.\n",
      "Start probability: 0.99. Resulting probability: 0.48. Cost: 24.\n",
      "\n",
      "Crafting adversarial example for example: 879.\n",
      "Start probability: 0.56. Resulting probability: 0.47. Cost: 1.\n",
      "\n",
      "Crafting adversarial example for example: 895.\n",
      "Start probability: 0.99. Resulting probability: 0.47. Cost: 20.\n",
      "\n",
      "Crafting adversarial example for example: 914.\n",
      "Start probability: 0.99. Resulting probability: 0.49. Cost: 14.\n",
      "\n",
      "Crafting adversarial example for example: 934.\n",
      "Start probability: 0.98. Resulting probability: 0.48. Cost: 15.\n",
      "\n",
      "Crafting adversarial example for example: 978.\n",
      "Start probability: 1.00. Resulting probability: 0.49. Cost: 26.\n"
     ]
    }
   ],
   "source": [
    "oracle = LogisticRegressionScikitSaliencyOracle(clf)\n",
    "manifest_set = get_manifest_set(label_encoder) # set containing manifest features\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    \n",
    "    # Transform the example from compressed matrix format to numpy array.\n",
    "    x = x.toarray()[0] \n",
    "    \n",
    "    if clf.predict([x]) == 1:\n",
    "        print('\\nCrafting adversarial example for example: {}.'.format(i))\n",
    "        try:\n",
    "            x_adv, cost = find_adversarial_grosse(\n",
    "                x, \n",
    "                clf, \n",
    "                oracle, \n",
    "                manifest_set, \n",
    "                target_confidence=0.5,\n",
    "                k=100\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        x_prob, x_adv_prob = clf.predict_proba([x])[0, 1], clf.predict_proba([x_adv])[0, 1]\n",
    "        print('Start probability: {:.2f}. Resulting probability: {:.2f}. Cost: {}.'.format(x_prob, x_adv_prob, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide implemention for A* search on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_default_context(use_empty_init=True)\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def increment(self):\n",
    "        self.cnt += 1\n",
    "        \n",
    "    def count(self):\n",
    "        return self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, x):\n",
    "        self.root = x\n",
    "\n",
    "    def expand(self, manifest_set):\n",
    "        \"\"\"Generate all children of the current node.\"\"\"\n",
    "        \n",
    "        # Increment the counter of expanded nodes.\n",
    "        counter = Counter.get_default()\n",
    "        counter.increment()\n",
    "        \n",
    "        children = []\n",
    "        \n",
    "        for feat_idx in manifest_set:\n",
    "            \n",
    "            # Skip if the feature is already set.\n",
    "            if self.root[feat_idx] == 1:\n",
    "                continue\n",
    "                \n",
    "            child = np.array(self.root)\n",
    "            child[feat_idx] = 1\n",
    "            children.append(child)\n",
    "            \n",
    "        return children\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Node({})'.format(self.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expand_fn(x, manifest_set, p_norm=1, **kwargs):\n",
    "    \"\"\"Wrap the example in `Node`, expand the node, and compute the costs.\n",
    "    \n",
    "    Returns a list of tuples (child, cost)\n",
    "    \"\"\"\n",
    "    node = Node(x, **kwargs)\n",
    "    children = node.expand(manifest_set)\n",
    "    costs = [np.linalg.norm(x - c, ord=p_norm) for c in children]         \n",
    "    return list(zip(children, costs))\n",
    "\n",
    "def _goal_fn(x, clf, target_confidence=0.5):\n",
    "    \"\"\"Tell whether the example has reached the goal.\"\"\"\n",
    "    return clf.predict_proba([x])[0, 1] <= target_confidence\n",
    "\n",
    "def _heuristic_fn(x, clf, manifest_set, epsilon, q_norm=np.inf):\n",
    "    \"\"\"Distance to the decision boundary of a logistic regression classifier.\n",
    "    \n",
    "    By default the distance is w.r.t. L1 norm. This means that the denominator\n",
    "    has to be in terms of the Holder dual norm (`q_norm`), so L-inf. I know,\n",
    "    this interface is horrible.\n",
    "    \n",
    "    NOTE: The value has to be zero if the example is already on the target side\n",
    "    of the boundary.\n",
    "    \"\"\"\n",
    "    score = clf.decision_function([x])[0]\n",
    "    if score <= 0:\n",
    "        return 0.0\n",
    "    h = np.abs(score) / np.linalg.norm(clf.coef_[0, list(manifest_set)], ord=q_norm)    \n",
    "    return h * epsilon\n",
    "\n",
    "def hash_fn(x):\n",
    "    \"\"\"Hash function for examples.\"\"\"\n",
    "    return hash(x.tostring())\n",
    "\n",
    "@profiled\n",
    "def find_adversarial(x, clf, manifest_set, epsilon, p_norm=1, q_norm=np.inf,\n",
    "                     target_confidence=0.5, return_path=False, **kwargs):\n",
    "    \"\"\"Transform an example until it is classified with target confidence.\"\"\" \n",
    "\n",
    "    if clf.predict_proba([x])[0, 1] <= target_confidence:\n",
    "        raise Exception('Initial example is already classified as bening.')        \n",
    "    return a_star_search(\n",
    "        start_node=x, \n",
    "        expand_fn=lambda x: _expand_fn(x, manifest_set, p_norm=p_norm, **kwargs), \n",
    "        goal_fn=lambda x: _goal_fn(x, clf, target_confidence), \n",
    "        heuristic_fn=lambda x: _heuristic_fn(x, clf, manifest_set, epsilon, q_norm=q_norm), \n",
    "        hash_fn=hash_fn,\n",
    "        return_path=return_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run experiments to compare JSMA with our heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = LogisticRegressionScikitSaliencyOracle(clf)\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    \n",
    "    # Transform the example from compressed matrix format to numpy array.\n",
    "    x = x.toarray()[0] \n",
    "\n",
    "    if clf.predict([x]) == 1:\n",
    "        print('\\nCrafting adversarial example for example: {}.'.format(i))\n",
    "        \n",
    "        # Try finding adversarial example using JSMA with distortion bound k = 100.\n",
    "        try:\n",
    "            x_adv_grosse, cost_grosse = find_adversarial_grosse(x, clf, oracle, manifest_set, k=100)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        # Try finding adversarial example using our heuristic with A* search.\n",
    "        x_adv, cost = find_adversarial(x, clf, p_norm=1, q_norm=np.inf)\n",
    "        \n",
    "        assert clf.predict([x_adv_grosse]) == 0 and clf.predict([x_adv]) == 0\n",
    "        \n",
    "        print('Cost using Grosse algorithm: {}. Using our heuristic: {}.'.format(cost_grosse, int(cost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design experiments to run as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=seed)\n",
    "\n",
    "def find_adv_examples(X, target_confidence, feat_count, p_norm=1, q_norm=np.inf):\n",
    "    \n",
    "    # List for storing the results.\n",
    "    results = []\n",
    "\n",
    "    # Indices of examples classified as malware.\n",
    "    neg_indices, = np.where(clf.predict_proba(X)[:, 1] > target_confidence)\n",
    "        \n",
    "    # Choose randomly 'feat_count' features to perturb.\n",
    "    manifest_subset = set(np.random.choice((list(manifest_set)), size=feat_count, replace=False))\n",
    "    assert len(manifest_subset) == feat_count\n",
    "\n",
    "    costs = {}\n",
    "\n",
    "    # Start by finding adversarial examples using JSMA and record their costs.\n",
    "    for idx in neg_indices:\n",
    "        x = X[idx].toarray()[0] \n",
    "\n",
    "        try:\n",
    "            x_adv_jsma, cost_jsma = find_adversarial_grosse(\n",
    "                x, \n",
    "                clf, \n",
    "                oracle, \n",
    "                manifest_subset, \n",
    "                target_confidence = target_confidence,\n",
    "                k=20\n",
    "            )\n",
    "\n",
    "            costs[idx] = cost_jsma\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Or check length\n",
    "    if not len(costs):\n",
    "        print('WARN! JSMA did not find any adversarial examples for feat_count = {}'.format(feat_count))\n",
    "        return None\n",
    "\n",
    "    # Now only look at the 10 malware samples with lowest path cost according to JSMA.\n",
    "    example_costs = sorted(costs.items(), key=lambda d: d[1])[:10]\n",
    "        \n",
    "    # Try finding adversarial example using our heuristic with different epsilon values.\n",
    "    epsilons = [50, 25, 10, 5, 2, 1]\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "\n",
    "        for idx, cost_jsma in example_costs:\n",
    "            \n",
    "            x = X[idx].toarray()[0]\n",
    "            \n",
    "            # Instantiate a counter for expanded nodes, and a profiler.\n",
    "            expanded_counter = Counter()\n",
    "            per_example_profiler = Profiler()\n",
    "            \n",
    "            with expanded_counter.as_default(), per_example_profiler.as_default():\n",
    "                x_adv, cost = find_adversarial(\n",
    "                    x, \n",
    "                    clf, \n",
    "                    manifest_subset, \n",
    "                    epsilon,\n",
    "                    p_norm=1, \n",
    "                    q_norm=np.inf\n",
    "                )\n",
    "                \n",
    "            nodes_expanded = expanded_counter.count()\n",
    "            runtime = per_example_profiler.compute_stats()['find_adversarial']['tot']\n",
    "            \n",
    "            print('(Epsilon: {}; Index: {}; Feat Count: {}). Cost using Grosse algorithm: {}. Using our heuristic: {}.'\n",
    "                  .format(epsilon, idx, feat_count, cost_jsma, int(cost)))\n",
    "\n",
    "            confidence_jsma = clf.predict_proba([x_adv_jsma])[0, 1]\n",
    "            confidence = clf.predict_proba([x_adv])[0, 1]\n",
    "            \n",
    "            result = {\n",
    "                'index': idx, \n",
    "                'feat_count': feat_count,\n",
    "                'manifest_subset': manifest_subset,\n",
    "                'x_adv_jsma': x_adv_jsma,\n",
    "                'path_cost_jsma': cost_jsma,\n",
    "                'confidence_jsma': confidence_jsma,\n",
    "                'runtime_jsma': None,\n",
    "                'x_adv': x_adv,\n",
    "                'path_cost': cost,\n",
    "                'confidence': confidence,\n",
    "                'nodes_expanded': None,\n",
    "                'epsilon': epsilon,\n",
    "                'runtime': runtime\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "    return results\n",
    "        \n",
    "\n",
    "# Number of features to perturb.\n",
    "feat_counts = np.arange(50, 101, 10)\n",
    "\n",
    "for feat_count in feat_counts:    \n",
    "    results = find_adv_examples(X, target_confidence=0.5, feat_count=feat_count)\n",
    "    print('Results are {}'.format(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
